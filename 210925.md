## DALL-E	

OpenAI에서 2021년 초에 공개한 머신러닝 모델로, 텍스트를 인풋으로 받아서 이미지를 생성하는 모델이다. GPT-3 (transformer) 를 기반으로 하는 모델이다. 전체 모델은 공개되어있지 않지만, 이미지를 보고 카테고리를 분류할 수 있는 CLIP 모델은 오픈소스로 공개되어있다. AI 커뮤니티의 여러 사람들이 이를 바탕으로 DALL-E와 비슷한 모델들을 만들어서 공개했다. DALL-E의 방식으로 이미지를 생성할 때에는 텍스트에서 바로 그럴듯한 이미지를 예측하는 것이 아니라 훈련과정을 거쳐야하기 때문에 실시간 생성이 불가능하고, 시간과 비용이 증가한다. [공식 블로그 글](https://openai.com/blog/clip/)

- [DALL-E pytorch](https://github.com/lucidrains/DALLE-pytorch) 버전 github repo
https://twitter.com/images_ai

## Big Sleep (VQGAN + CLIP)
- 쉽게 설명한 Max Woolf [블로그 글](https://minimaxir.com/2021/08/vqgan-clip/). 다양한 링크 포함. 이분의 [colab notebook](https://colab.research.google.com/drive/1wkF67ThUz37T2_oPIuSwuO4e_-0vjaLs?usp=sharing#scrollTo=R7LwGXVwxoS9)
- VQGAN의 [더 자세한 설명 블로그 글](https://ljvmiranda921.github.io/notebook/2021/08/08/clip-vqgan/)
- Big Sleep [쉽고 짧게 설명한 글](https://www.digitaltrends.com/news/big-sleep-ai-image-generator/)
- BigGAN [설명](https://www.aiweirdness.com/welcome-to-latent-space-19-01-26/)
- 모델을 만든 사람의 [트위터](https://twitter.com/advadnoun/)
- The Big Sleep: BigGANxCLIP [colab notebook](https://colab.research.google.com/drive/1NCceX2mbiKOSlAd_o7IU7nA9UskKN5WR?usp=sharing)
- 모델 [사용 팁](https://www.reddit.com/r/MediaSynthesis/comments/l2hmqn/this_aint_it_chief/gk8g8e9/)
- 잘 작동하는 [1000개 카테고리](https://www.reddit.com/r/MediaSynthesis/comments/l7hbix/tip_for_users_of_the_big_sleep_it_should_on/) 참고
- CLIP을 사용한 [프로젝트 리스트](https://www.reddit.com/r/MachineLearning/comments/ldc6oc/p_list_of_sitesprogramsprojects_that_use_openais/)
- [r/bigsleep](https://www.reddit.com/r/bigsleep/)
- [r/deepdream](https://www.reddit.com/r/deepdream/)
- [r/mediasynthsis](https://www.reddit.com/r/MediaSynthesis/) 고품질 이미지 위주.
- https://www.reddit.com/r/MachineLearning/comments/kzr4mg/p_the_big_sleep_texttoimage_generation_using/


