## DALL-E	

OpenAI에서 2021년 초에 공개한 머신러닝 모델로, 텍스트를 인풋으로 받아서 이미지를 생성하는 모델이다. GPT-3 (transformer) 를 기반으로 하는 모델이다. 전체 모델은 공개되어있지 않지만, 이미지를 보고 카테고리를 분류할 수 있는 CLIP 모델은 오픈소스로 공개되어있다. AI 커뮤니티의 여러 사람들이 이를 바탕으로 DALL-E와 비슷한 모델들을 만들어서 공개했다. DALL-E의 방식으로 이미지를 생성할 때에는 텍스트에서 바로 그럴듯한 이미지를 예측하는 것이 아니라 훈련과정을 거쳐야하기 때문에 실시간 생성이 불가능하고, 시간과 비용이 증가한다.

https://twitter.com/images_ai

## Big Sleep (VQGAN + CLIP)
https://minimaxir.com/2021/08/vqgan-clip/
: 쉽게 설명한 블로그 글. 다양한 링크 포함.

https://twitter.com/advadnoun/
: 모델을 만든 사람의 트위터

https://colab.research.google.com/drive/1NCceX2mbiKOSlAd_o7IU7nA9UskKN5WR?usp=sharing
: The Big Sleep: BigGANxCLIP 노트북

https://www.reddit.com/r/MediaSynthesis/comments/l2hmqn/this_aint_it_chief/gk8g8e9/
: 사용 팁

https://www.reddit.com/r/MediaSynthesis/comments/l7hbix/tip_for_users_of_the_big_sleep_it_should_on/
: 1000개 카테고리 참고
